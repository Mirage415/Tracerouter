<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <title>Voice Control Traceroute Visualization</title>
  <!-- Basic Libraries -->
  <!-- 只保留p5.js和p5.sound.min.js，用于动画显示 -->
  <script src="lib/p5/p5.min.js"></script>
  <script src="lib/p5/addons/p5.sound.min.js"></script>

  <!-- 引入nodejs-whisper相关的库 -->
  <script src="../node_modules/nodejs-whisper/dist/nodejs-whisper.js"></script>

  <style>
    body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: #111;
      color: #fff;
      font-family: Arial, sans-serif;
    }

    #ui-panel {
      position: absolute;
      left: 20px;
      top: 20px;
      z-index: 10;
      background: rgba(0, 0, 0, 0.7);
      padding: 15px;
      border-radius: 10px;
      width: 300px;
    }

    #control-buttons {
      display: flex;
      gap: 10px;
      margin-bottom: 10px;
    }

    button {
      background: #05c9fa;
      color: white;
      border: none;
      padding: 8px 12px;
      border-radius: 5px;
      cursor: pointer;
      font-weight: bold;
    }

    button:disabled {
      background: #666;
      cursor: not-allowed;
    }

    #result {
      margin-top: 10px;
      font-size: 1.2em;
      background: rgba(255, 255, 255, 0.1);
      padding: 10px;
      border-radius: 5px;
      min-height: 1.5em;
    }

    /* Result label styles */
    .result-label {
      font-size: 0.8em;
      color: #05c9fa;
      margin-bottom: 5px;
      font-weight: bold;
    }

    /* Enhanced result area styles */
    .result-content {
      padding: 8px;
      background: rgba(5, 201, 250, 0.1);
      border-left: 3px solid #05c9fa;
      word-break: break-all;
    }

    #output-panel {
      position: absolute;
      left: 20px;
      top: 180px;
      z-index: 10;
      background: rgba(0, 0, 0, 0.7);
      padding: 15px;
      border-radius: 10px;
      width: 400px;
      max-height: 60vh;
      overflow-y: auto;
    }

    #traceOutput {
      font-family: monospace;
      white-space: pre-wrap;
      font-size: 0.9em;
      color: #ddd;
    }

    #debugPanel {
      position: absolute;
      right: 20px;
      top: 20px;
      z-index: 10;
      background: rgba(0, 0, 0, 0.7);
      padding: 15px;
      border-radius: 10px;
      width: 300px;
      max-height: 60vh;
      overflow-y: auto;
    }

    #debugOutput {
      font-family: monospace;
      white-space: pre-wrap;
      font-size: 0.9em;
      color: #0f0;
    }

    h3 {
      margin-top: 0;
      color: #05c9fa;
    }

    #rawInput {
      margin-top: 10px;
      width: 90%;
      padding: 8px;
      background: rgba(255, 255, 255, 0.2);
      border: none;
      border-radius: 5px;
      color: white;
    }

    #submitBtn {
      margin-top: 5px;
    }
  </style>
</head>

<body>
  <div id="ui-panel">
    <h3>Voice Control Traceroute</h3>
    <div id="control-buttons">
      <button id="startBtn">🎙️ Start Recognition</button>
      <button id="stopBtn" disabled>⏹️ Stop Recognition</button>
      <button id="testBtn">Test API</button>
    </div>
    <div id="result">
      <div class="result-label">Recognition Result</div>
      <div class="result-content">(Not started)</div>
    </div>
    <p style="font-size:0.8em;color:#ccc;">Say a domain name, for example: "google.com" or "baidu"</p>

    <!-- Add manual input field -->
    <input type="text" id="rawInput" placeholder="Or directly enter domain name...">
    <button id="submitBtn">Submit</button>
  </div>

  <div id="output-panel" style="top: 300px;">
    <h3>Execution Result:</h3>
    <div id="traceOutput"></div>
  </div>

  <!-- Debug information panel -->
  <div id="debugPanel">
    <h3>Debug Information:</h3>
    <div id="debugOutput">Waiting for debug info...</div>
    <!-- Add dedicated recognition result debug area -->
    <h3 style="margin-top: 15px; color: #ff0;">Recognition Text Debug:</h3>
    <div id="recognitionDebug"
      style="color: #ff0; font-weight: bold; background: rgba(0,0,0,0.5); padding: 8px; margin-top: 5px;">Waiting for
      voice input...
    </div>
  </div>

  <script>
    // Auto-execute traceroute when input changes and loses focus or Enter key is pressed
    const rawInput = document.getElementById('rawInput');
    rawInput.addEventListener('change', () => {
      const domain = rawInput.value.trim();
      if (domain) {
        debugLog(`Auto input domain: ${domain}`);
        const resultElement = document.getElementById('result');
        let resultContent = resultElement.querySelector('.result-content');
        if (resultContent) {
          resultContent.textContent = domain;
        } else {
          resultElement.innerHTML = `<div class="result-label">Recognition Result</div><div class="result-content">${domain}</div>`;
        }
        processCommand(domain);
        rawInput.value = '';
      }
    });
    rawInput.addEventListener('keypress', (e) => {
      if (e.key === 'Enter') {
        const domain = rawInput.value.trim();
        if (domain) {
          debugLog(`Auto input domain: ${domain}`);
          const resultElement = document.getElementById('result');
          let resultContent = resultElement.querySelector('.result-content');
          if (resultContent) {
            resultContent.textContent = domain;
          } else {
            resultElement.innerHTML = `<div class="result-label">Recognition Result</div><div class="result-content">${domain}</div>`;
          }
          processCommand(domain);
          rawInput.value = '';
        }
      }
    });
  </script>

  <script>
    // Add debug log function
    function debugLog(message) {
      const debugElem = document.getElementById('debugOutput');
      const timestamp = new Date().toLocaleTimeString();
      debugElem.innerHTML += `[${timestamp}] ${message}\n`;
      debugElem.scrollTop = debugElem.scrollHeight;
      console.log(`[DEBUG] ${message}`);
    }

    // Add dedicated recognition text log function
    function recognitionLog(text) {
      const recognitionDebug = document.getElementById('recognitionDebug');
      if (recognitionDebug) {
        recognitionDebug.innerHTML = `<span style="color:#f0f;">"${text || 'No text'}"</span>`;
        console.log(`[RECOGNITION] "${text}"`);
      }
    }

    // Nodejs-Whisper 语音识别相关代码
    let isRecognizing = false;
    let audioRecorder = null;
    let audioChunks = [];
    let tempAudioFile = null;

    // 初始化语音识别
    async function initAudioCapture() {
      try {
        debugLog("正在初始化音频捕获...");

        // 尝试使用Web Speech API作为备选方案
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
          debugLog("检测到Web Speech API可用，将作为备选方案");
          window.webSpeechBackup = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
          window.webSpeechBackup.lang = 'zh-CN'; // 设置为中文
          window.webSpeechBackup.continuous = false;
          window.webSpeechBackup.interimResults = false;

          window.webSpeechBackup.onresult = function (event) {
            const transcript = event.results[0][0].transcript;
            debugLog(`Web Speech API 识别结果: "${transcript}"`);
            recognitionLog(transcript);

            // 更新UI
            const resultElement = document.getElementById('result');
            let resultContent = resultElement.querySelector('.result-content');
            if (resultContent) {
              resultContent.textContent = transcript || '(未检测到语音)';
            } else {
              resultElement.innerHTML = `<div class="result-label">识别结果</div><div class="result-content">${transcript || '(未检测到语音)'}</div>`;
            }

            // 处理命令
            if (transcript) {
              processCommand(transcript);
            }
          };

          window.webSpeechBackup.onerror = function (event) {
            debugLog(`Web Speech API 错误: ${event.error}`);
          };
        }

        // 获取麦克风流
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        debugLog("麦克风访问权限已获取");

        // 创建MediaRecorder
        audioRecorder = new MediaRecorder(stream);

        // 监听数据可用事件
        audioRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
          }
        };

        // 监听录音停止事件
        audioRecorder.onstop = async () => {
          if (audioChunks.length === 0) {
            debugLog("没有收集到音频数据");
            return;
          }

          try {
            debugLog("开始处理音频...");
            const resultElement = document.getElementById('result');
            let resultContent = resultElement.querySelector('.result-content');
            if (resultContent) {
              resultContent.textContent = "正在识别...";
            }

            // 创建音频Blob
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            audioChunks = []; // 清空数组以便下次录音

            // 在Electron环境中处理音频 
            if (hasElectronAPI) {
              // 向主进程发送音频数据进行处理
              debugLog("发送音频到主进程进行Whisper处理");

              // 将Blob转换为ArrayBuffer
              const arrayBuffer = await audioBlob.arrayBuffer();
              const uint8Array = new Uint8Array(arrayBuffer);

              // 使用临时文件保存音频
              const tempFileName = `temp_audio_${Date.now()}.wav`;

              // 通过Electron IPC调用nodejs-whisper处理
              // 这需要在preload.js和main.js中添加相应的API
              window.api.processWhisperAudio(uint8Array, tempFileName)
                .then(transcription => {
                  debugLog(`Whisper识别结果: "${transcription}"`);

                  // 更新UI
                  if (resultContent) {
                    resultContent.textContent = transcription || '(未检测到语音)';
                  }

                  // 识别到内容后处理命令
                  if (transcription) {
                    processCommand(transcription);
                  }

                  // 如果仍处于识别状态，继续录音
                  if (isRecognizing) {
                    startRecording();
                  }
                })
                .catch(error => {
                  debugLog(`音频处理错误: ${error.message}`);
                  console.error("音频处理错误:", error);

                  // 尝试使用Web Speech API作为备选
                  if (window.webSpeechBackup) {
                    debugLog("尝试使用Web Speech API作为备选方案");
                    try {
                      window.webSpeechBackup.start();
                      debugLog("已启动Web Speech API备选识别");
                    } catch (webError) {
                      debugLog(`Web Speech API启动失败: ${webError.message}`);
                    }
                  }
                });
            } else {
              debugLog("无法处理音频：Electron API不可用");
              if (resultContent) {
                resultContent.textContent = "无法处理音频：Electron API不可用";
              }
            }
          } catch (error) {
            debugLog(`音频处理错误: ${error.message}`);
            console.error("音频处理错误:", error);
          }
        };

        return true;
      } catch (error) {
        debugLog(`音频捕获初始化失败: ${error.message}`);
        console.error("音频捕获初始化错误:", error);
        return false;
      }
    }

    // 开始录音
    function startRecording() {
      if (!audioRecorder || audioRecorder.state === 'recording') {
        return;
      }

      try {
        audioChunks = [];
        audioRecorder.start();
        debugLog("开始录音...");

        // 设置一个超时，5秒停止一次录音并进行处理
        setTimeout(() => {
          if (audioRecorder && audioRecorder.state === 'recording') {
            audioRecorder.stop();
            debugLog("录音段已结束，正在处理...");
          }
        }, 5000);
      } catch (error) {
        debugLog(`开始录音失败: ${error.message}`);
      }
    }

    // 停止录音
    function stopRecording() {
      if (!audioRecorder || audioRecorder.state !== 'recording') {
        return;
      }

      try {
        audioRecorder.stop();
        debugLog("录音已停止");

        // 同时停止Web Speech API备选方案
        if (window.webSpeechBackup) {
          try {
            window.webSpeechBackup.stop();
            debugLog("Web Speech API备选方案已停止");
          } catch (e) {
            debugLog(`停止Web Speech API错误: ${e.message}`);
          }
        }
      } catch (error) {
        debugLog(`停止录音失败: ${error.message}`);
      }
    }

    // Process domain formatting
    function formatDomain(text) {
      // Remove possible "traceroute" keyword
      let domain = text.toLowerCase().replace(/traceroute\s+/g, '').trim();

      // Remove trailing punctuation (like period, comma, exclamation mark, etc.)
      domain = domain.replace(/[.,!?;:'"）】》〉）]\s*$/g, '').trim();

      // Remove punctuation and special characters from the beginning and end
      domain = domain.replace(/^[\s"'《【（\['"\(]+|[\s"'》】）\]'"\)]+$/g, '').trim();

      // Handle common domain shortcuts
      const domainMap = {
        'google': 'google.com',
        'baidu': 'baidu.com',
        'bing': 'bing.com',
        'yahoo': 'yahoo.com',
        'taobao': 'taobao.com',
        'microsoft': 'microsoft.com',
        'tencent': 'qq.com',
        'netease': '163.com'
      };

      // Check if it's a common domain shortcut
      if (domainMap[domain]) {
        domain = domainMap[domain];
      }

      // If there's no .com, .cn or other suffix, automatically add .com
      if (!/\.\w+$/.test(domain)) {
        domain = domain + '.com';
      }

      // Ensure domain format is correct (only contains letters, numbers, dots and hyphens)
      if (!/^[a-z0-9.-]+\.[a-z]{2,}$/i.test(domain)) {
        // Try to fix common issues
        domain = domain
          // Remove all spaces
          .replace(/\s+/g, '')
          // Reduce multiple dots to a single dot
          .replace(/\.{2,}/g, '.')
          // Clean trailing dots
          .replace(/\.$/, '');
      }

      debugLog(`原始输入: "${text}" -> 处理后域名: "${domain}"`);
      return domain;
    }

    // Check if Electron API is available (running in packaged app)
    const hasElectronAPI = window.api && window.api.runTraceroute && window.api.onOutput;
    debugLog(`Electron API 可用: ${hasElectronAPI}`);
    if (!hasElectronAPI) {
      debugLog("警告: Electron API 不可用，某些功能将无法工作");
    }

    // Process recognized command
    function processCommand(txt) {
      // Standardize as domain format
      const domain = formatDomain(txt);
      debugLog(`处理后域名: ${domain}`);

      // Construct complete traceroute command
      const command = `traceroute ${domain}`;

      if (hasElectronAPI) {
        debugLog(`执行命令: ${command}`);
        document.getElementById('traceOutput').innerHTML = `执行: ${command}\n正在追踪路由...\n`;
        // Call main process through API exposed in preload.js
        window.api.runTraceroute(command);
      } else {
        debugLog(`无法执行命令: Electron API 不可用`);
        document.getElementById('traceOutput').innerHTML = "错误: Electron API 不可用，无法执行命令\n";
      }
    }

    // 添加按钮事件处理
    document.getElementById('startBtn').onclick = async () => {
      try {
        debugLog("开始语音识别...");

        // 初始化音频捕获（如果未初始化）
        if (!audioRecorder) {
          const audioInitialized = await initAudioCapture();
          if (!audioInitialized) {
            throw new Error("无法初始化音频捕获");
          }
        }

        // 更新UI
        const resultElement = document.getElementById('result');
        let resultContent = resultElement.querySelector('.result-content');
        if (resultContent) {
          resultContent.textContent = '正在听...';
        } else {
          resultElement.innerHTML = `<div class="result-label">识别结果</div><div class="result-content">正在听...</div>`;
        }

        document.getElementById('startBtn').disabled = true;
        document.getElementById('stopBtn').disabled = false;

        // 设置识别状态并开始录音
        isRecognizing = true;
        startRecording();

      } catch (error) {
        debugLog(`启动语音识别失败: ${error.message}`);
        console.error("语音识别启动错误:", error);

        const resultElement = document.getElementById('result');
        let resultContent = resultElement.querySelector('.result-content');
        if (resultContent) {
          resultContent.textContent = `启动失败: ${error.message}`;
        } else {
          resultElement.innerHTML = `<div class="result-label">识别结果</div><div class="result-content">启动失败: ${error.message}</div>`;
        }

        document.getElementById('startBtn').disabled = false;
        document.getElementById('stopBtn').disabled = true;
      }
    };

    document.getElementById('stopBtn').onclick = () => {
      debugLog("停止语音识别");

      // 停止录音
      stopRecording();

      // 更新状态
      isRecognizing = false;

      // 更新UI
      const resultElement = document.getElementById('result');
      let resultContent = resultElement.querySelector('.result-content');
      if (resultContent) {
        const currentText = resultContent.textContent;
        if (currentText && currentText !== '(已停止)' && !currentText.endsWith('(已停止)')) {
          resultContent.textContent = `${currentText} (已停止)`;
        } else if (!currentText || currentText === '(等待识别...)') {
          resultContent.textContent = '(已停止)';
        }
      } else {
        resultElement.innerHTML = `<div class="result-label">识别结果</div><div class="result-content">(已停止)</div>`;
      }

      document.getElementById('startBtn').disabled = false;
      document.getElementById('stopBtn').disabled = true;
    };

    // Test API button
    document.getElementById('testBtn').onclick = () => {
      debugLog("Test button clicked");
      const testDomain = "google.com";
      const resultElement = document.getElementById('result');
      let resultContent = resultElement.querySelector('.result-content');
      if (resultContent) {
        resultContent.textContent = testDomain;
      } else {
        resultElement.innerHTML = `<div class="result-label">Recognition Result</div><div class="result-content">${testDomain}</div>`;
      }
      processCommand(testDomain);
    };

    // Manual input submit button
    document.getElementById('submitBtn').onclick = () => {
      const inputField = document.getElementById('rawInput');
      const domain = inputField.value.trim();
      if (domain) {
        debugLog(`Manual domain input: ${domain}`);
        const resultElement = document.getElementById('result');
        let resultContent = resultElement.querySelector('.result-content');
        if (resultContent) {
          resultContent.textContent = domain;
        } else {
          resultElement.innerHTML = `<div class="result-label">Recognition Result</div><div class="result-content">${domain}</div>`;
        }
        processCommand(domain);
        // Clear input field
        inputField.value = '';
      } else {
        debugLog("No domain entered");
      }
    };

    // Allow Enter key for submission
    document.getElementById('rawInput').addEventListener('keypress', (e) => {
      if (e.key === 'Enter') {
        document.getElementById('submitBtn').click();
      }
    });

    function gotSpeech() {
      debugLog("Received p5 speech recognition result");
      // Add more detailed debug information
      debugLog(`speechRec status: resultValue=${speechRec.resultValue}, resultString=${speechRec.resultString}, isRecognizing=${isRecognizing}`);

      // Display original resultString directly, whether it has a value or not
      recognitionLog(speechRec.resultString);

      // Key modification: display results regardless of isRecognizing status
      // if (isRecognizing) {
      if (speechRec.resultString) {  // As long as there's a result, display and process
        const txt = speechRec.resultString.trim();
        debugLog(`p5 recognition text: "${txt}"`);
        textResult = txt;

        // Update the way recognition results are displayed
        const resultElement = document.getElementById('result');
        // Keep label, only update content part
        let resultContent = resultElement.querySelector('.result-content');
        if (resultContent) {
          resultContent.textContent = txt || '(Waiting for recognition...)';
        } else {
          // If result-content element not found, fall back to old way
          resultElement.innerHTML = `<div class="result-label">Recognition Result</div><div class="result-content">${txt || '(Waiting for recognition...)'}</div>`;
        }

        // Only process command when text is not empty
        if (txt) {
          processCommand(txt);
        }
      } else {
        debugLog(`p5 speech recognition stopped or no result: isRecognizing=${isRecognizing}`);
      }
    }

    // If in Electron environment, set callback to receive output
    if (hasElectronAPI) {
      debugLog("Setting up Electron API output callback");
      window.api.onOutput((data) => {
        debugLog(`Received output: ${data.substring(0, 50)}...`);
        const outputElem = document.getElementById('traceOutput');
        outputElem.innerHTML += data;
        outputElem.scrollTop = outputElem.scrollHeight; // Automatically scroll to bottom
      });
    } else {
      document.getElementById('traceOutput').innerHTML = "Electron API not detected, cannot execute traceroute command.";
    }

    // Check browser speech recognition support
    debugLog("Using p5.speech for speech recognition");

    // Waveform animation part
    let curves = 150;
    let cx, cy;
    let angles = [], baseRs = [], phases1 = [], phases2 = [], speeds1 = [], speeds2 = [];
    let mic; // Declare mic here so it's accessible in draw()

    function setup() {
      createCanvas(windowWidth, windowHeight);
      cx = width / 2;
      cy = height / 2;
      for (let i = 0; i < curves; i++) {
        angles.push(map(i, 0, curves, 0, TWO_PI));
        baseRs.push(random(height * 0.15, height * 0.3));
        phases1.push(random(TWO_PI));
        phases2.push(random(TWO_PI));
        speeds1.push(random(0.02, 0.08));
        speeds2.push(random(0.02, 0.08));
      }
      stroke(255);

      // Initialize and start p5.AudioIn
      mic = new p5.AudioIn();
      mic.start();

      debugLog("p5.js canvas initialization complete and mic started");
    }

    function draw() {
      background(20);
      let vol = mic ? mic.getLevel() : 0;
      // Occasionally record volume level
      if (frameCount % 60 === 0 && mic) {
        debugLog(`Current microphone volume: ${vol.toFixed(4)}`);
      }

      let maxAmp = map(vol, 0, 0.3, 0, height * 0.15);
      for (let i = 0; i < curves; i++) {
        phases1[i] += speeds1[i];
        phases2[i] += speeds2[i];
        let r = baseRs[i];
        let off1 = 50 * sin(phases1[i]) * maxAmp + 5 * sin(random(5, 15));
        let off2 = 50 * sin(phases2[i]) * maxAmp + 5 * sin(random(5, 15));
        let cp1x = cx + cos(angles[i]) * (r + off1);
        let cp1y = cy + sin(angles[i]) * (r + off1);
        let cp2x = cx + cos(angles[i]) * (r + off2);
        let cp2y = cy + sin(angles[i]) * (r + off2);
        stroke('#05c9fa');
        bezier(cx, cy, cp1x, cp1y, cp2x, cp2y, cx, cy);
      }
    }

    function windowResized() {
      resizeCanvas(windowWidth, windowHeight);
      cx = width / 2;
      cy = height / 2;
      debugLog("Window resized, canvas reset");
    }

    // Page load complete
    window.onload = function () {
      debugLog("Page loading complete");

      // Check if p5.speech is loaded correctly
      if (typeof p5.SpeechRec !== 'function') {
        debugLog("Error: p5.speech library not loaded correctly");
        document.getElementById('debugOutput').innerHTML += '<div style="color:red;font-weight:bold">Warning: p5.speech library not loaded correctly, speech recognition feature will not be available</div>';
      } else {
        debugLog("p5.speech library loaded correctly");
        // Check if speechRec is the expected object
        const testRec = new p5.SpeechRec();
        debugLog(`p5.SpeechRec test: ${Object.keys(testRec).join(", ")}`);
      }

      // Check AudioContext support
      if (typeof window.AudioContext !== 'undefined' || typeof window.webkitAudioContext !== 'undefined') {
        debugLog("Browser supports AudioContext");
      } else {
        debugLog("Warning: Browser does not support AudioContext, speech recognition may not work");
      }
    };
  </script>
</body>

</html>